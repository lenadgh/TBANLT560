---
title: "Project2"
author: "Lena Dam"
date: "2023-03-15"
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = normalizePath("C:/Users/lenad/localdocuments/3Q22/560")) 
knitr::opts_chunk$set(options(width = 1200))
library(tidyverse)
require(mlbench)
library(e1071)
library(nnet)
library(neuralnet)
library(klaR)
library(MASS)
library(randomForest)
library(rpart)
library(caret)
```

```{r}



# load the data set
data(BreastCancer)
ls(BreastCancer)
# some algorithms don't like missing values, so remove rows with missing values
BreastCancer <- na.omit(BreastCancer) 
# remove the unique identifier, which is useless and would confuse the machine learning algorithms
BreastCancer$Id <- NULL 

View(BreastCancer)


#svm
mysvm <- svm(Class ~ ., BreastCancer)
mysvm.pred <- predict(mysvm, BreastCancer)
table(mysvm.pred,BreastCancer$Class)

#nb
mynb <- NaiveBayes(Class ~ . , BreastCancer)
mynb.pred <- predict(mynb, BreastCancer)
table(mynb.pred$class, BreastCancer$Class)


str(BreastCancer)
for (i in c(1:9)){
BreastCancer[,i] <-(as.numeric(BreastCancer[,i])-min(as.numeric(BreastCancer[,i]))) /
  (max(as.numeric(BreastCancer[,i]))-min(as.numeric(BreastCancer[,i])))
}
mynnet <- nnet(Class ~ . , BreastCancer, size=5)

mynnet.pred <- predict(mynnet,BreastCancer,type="class")
table(mynnet.pred,BreastCancer$Class)



#Decision trees
mytree <- rpart(Class ~ ., BreastCancer)
plot(mytree); text(mytree) 
summary(mytree)
mytree.pred <- predict(mytree,BreastCancer,type="class")
table(mytree.pred,BreastCancer$Class)


# Leave-1-Out Cross Validation (LOOCV)
ans <- numeric(length(BreastCancer[,1]))
for (i in 1:length(BreastCancer[,1])) {
  mytree <- rpart(Class ~ ., BreastCancer[-i,])
  mytree.pred <- predict(mytree,BreastCancer[i,],type="class")
  ans[i] <- mytree.pred
}
ans <- factor(ans,labels=levels(BreastCancer$Class))
table(ans,BreastCancer$Class)

# The same as above in this case


#Quadratic Discriminant Analysis

myqda <- qda(Species ~ ., iris)
myqda.pred <- predict(myqda, iris)
table(myqda.pred$class,iris$Species)

myqda <- qda(Class ~ ., BreastCancer)
myqda.pred <- predict(myqda, BreastCancer)
head(myqda.pred$class)
table(myqda.pred$class,BreastCancer$Class)


#Redundancy Analysis

myrda <- rda(Class ~ ., BreastCancer)
myrda.pred <- predict(myrda, BreastCancer)

table(myrda.pred$class,BreastCancer$Class)

#Random Forests

myrf <- randomForest(Class ~ ., BreastCancer)
myrf.pred <- predict(myrf, BreastCancer)
head(myrf.pred)
table(myrf.pred, BreastCancer$Class)

#combining classes
combine.classes<-data.frame(myrf.pred, myrda.pred$class,#myqda.pred, 
                            mytree.pred,mynnet.pred,mysvm.pred, mynb.pred$class)
head(combine.classes)
head(myrf.pred)
head(myrda.pred)
combine.classes$myrf.pred<-ifelse(combine.classes$myrf.pred=="benign", 0, 1)
combine.classes[,2]<-ifelse(combine.classes[,2]=="benign", 0, 1)
combine.classes[,3]<-ifelse(combine.classes[,3]=="benign", 0, 1)
combine.classes[,4]<-ifelse(combine.classes[,4]=="benign", 0, 1)
combine.classes[,5]<-ifelse(combine.classes[,5]=="benign", 0, 1)
combine.classes[,6]<-ifelse(combine.classes[,6]=="benign", 0, 1)
str(combine.classes)
combine.cl<-combine.classes[, -c(7,8)]
majority.vote=rowSums(combine.classes[,-c(7,8)])
head(majority.vote)
combine.classes[,7]<-rowSums(combine.classes[,-c(7,8)])
combine.classes[,8]<-ifelse(combine.classes[,7]>=4, "malignant", "benign")
table(combine.classes[,8], BreastCancer$Class)



confusionMatrix(as.factor(combine.classes[,8]), as.factor(BreastCancer$Class))

```

